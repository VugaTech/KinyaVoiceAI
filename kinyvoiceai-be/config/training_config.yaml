model:
  name: "wav2vec2-base" # Pre-trained model architecture (e.g., wav2vec 2.0 base model)
  pretrained_path: "/app/models/pretrained/wav2vec2-base.pt" # Path to pre-trained weights (optional; adjust if using a specific checkpoint)
  freeze_base: false # Allow fine-tuning of the base model
  output_dir: "/app/models/checkpoints/" # Directory to save trained model checkpoints

training:
  learning_rate: 5e-5 # Initial learning rate for optimizer
  batch_size: 16 # Batch size per device (adjust based on GPU memory)
  epochs: 10 # Number of training epochs
  optimizer: "adamw" # Optimizer (AdamW is common for transformers)
  scheduler: "linear" # Learning rate scheduler type
  warmup_steps: 500 # Number of warmup steps for the scheduler
  max_grad_norm: 1.0 # Gradient clipping to prevent exploding gradients
  device: "cuda" # Training device (set to "cpu" if no GPU available)

data:
  train_path: "/app/data/train.tsv" # Path to training data split
  dev_path: "/app/data/devtest.tsv" # Path to validation (devtest) data split
  sample_rate: 16000 # Audio sample rate in Hz (matches dataset standard)
  max_audio_length: 30 # Maximum audio length in seconds (per dataset: 10-30s)

logging:
  log_dir: "/app/logs/" # Directory for saving training logs
  experiment_tracker: "wandb" # Use Weights & Biases for experiment tracking (required for Tracks A and B)
  project_name: "kinyavoiceai" # Project name for tracking
  log_frequency: 100 # Log metrics every 100 steps

evaluation:
  eval_frequency: 500 # Evaluate on dev set every 500 steps
  metrics: ["wer", "cer"] # Compute Word Error Rate and Character Error Rate